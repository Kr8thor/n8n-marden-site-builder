[{"createdAt":"2025-05-15T23:58:55.713Z","updatedAt":"2025-05-16T00:01:01.000Z","id":"oHTdmhAXjU2PtZlz","name":"ELC white updated copy","active":true,"nodes":[
  {
    "parameters":{
      "httpMethod":"POST",
      "path":"api-trigger-elc-seo",
      "options":{
        "responseMode":"onReceived"
      }
    },
    "name":"Webhook Trigger",
    "type":"n8n-nodes-base.webhook",
    "typeVersion":1,
    "position":[-1400,20],
    "id":"cf2f5f7f-0000-0000-0000-000000000001",
    "webhookId":"api-trigger-elc-seo"
  },
{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":2},"conditions":[{"id":"4d6eb54d-934e-4222-b86c-af633d2ed051","leftValue":"={{ $json.pageUrl }}","rightValue":"elc-in-the-news","operator":{"type":"string","operation":"notContains"}},{"id":"1cbf9556-93fc-47fb-a7d3-3b3ec2960e75","leftValue":"={{ $json.pageUrl }}","rightValue":"blog","operator":{"type":"string","operation":"notContains"}},{"id":"ca809f03-e65b-4f06-9638-b3921704eb55","leftValue":"={{ $json.pageUrl }}","rightValue":"events","operator":{"type":"string","operation":"notContains"}},{"id":"21c4acbe-3513-47a6-8c6c-9fc4b9ae3728","leftValue":"={{ $json.pageUrl }}","rightValue":"international-law","operator":{"type":"string","operation":"notContains"}}],"combinator":"and"},"options":{}},"type":"n8n-nodes-base.filter","typeVersion":2.2,"position":[-400,180],"id":"14e8fbfe-1075-4f68-a6a0-16d8c20cc7e6","name":"Filter"},{"parameters":{"mode":"combine","combinationMode":"multiplex","options":{}},"name":"Merge URL Sources","type":"n8n-nodes-base.merge","typeVersion":2,"position":[-580,160],"id":"4dc2d606-bad5-4871-aeb3-3ad12b7390eb","alwaysOutputData":true},{"parameters":{"mode":"combine","mergeByFields":{"values":[{"field1":"lcpImageUrl","field2":"lcpImageUrl"}]},"options":{"multipleMatches":"first"}},"name":"Merge Image Data","type":"n8n-nodes-base.merge","typeVersion":2,"position":[100,420],"id":"c9fe6ffb-f824-4b67-824c-35a3e19b96f4","alwaysOutputData":true},{"parameters":{"jsCode":"// Get input items and include special exception URLs\nconst items = $input.all();\n\n// Process items to ensure URLs are properly presented\nconst processedItems = items.map(item => {\n  // Ensure the URL is specific and not just the base domain\n  let url = item.json.pageUrl || '';\n  \n  // Special handling for fellowship URL\n  if (url === 'https://www.earthlawcenter.org' && items.some(i => i.json.pageUrl && i.json.pageUrl.includes('/earth-lawyers-fellowship'))) {\n    console.log('Prioritizing earth-lawyers-fellowship URL over base domain');\n    url = 'https://www.earthlawcenter.org/earth-lawyers-fellowship';\n  }\n  \n  return {\n    json: {\n      ...item.json,\n      pageUrl: url\n    }\n  };\n});\n\n// Print diagnostic info\nconsole.log(`Processed ${processedItems.length} URLs with proper pages`);\n\nreturn processedItems;"},"name":"Data validation node","type":"n8n-nodes-base.code","typeVersion":2,"position":[640,200],"id":"edb4b228-d1ec-47be-bf4c-0c2f2656f441","alwaysOutputData":true},{"parameters":{"jsCode":"// Format data as CSV\nconst items = $input.all();\nconst timestamp = new Date().toISOString().replace(/:/g, '-').split('.')[0];\n\n// Create CSV header\nconst csvHeader = \"pageUrl,lcpImageUrl,imageSizeKB,lcpScore,lcpMs,dateCaptured\\n\";\n\n// Create CSV rows\nconst csvRows = items.map(item => {\n  // Escape fields that might contain commas\n  const escapeCsv = (str) => {\n    if (!str) return '';\n    if (str.includes(',') || str.includes('\"') || str.includes('\\n')) {\n      return `\"${str.replace(/\"/g, '\"\"')}\"`;\n    }\n    return str;\n  };\n  \n  // Format row with proper escaping\n  const row = [\n    escapeCsv(item.json.pageUrl || ''),\n    escapeCsv(item.json.lcpImageUrl || ''),\n    item.json.imageSizeKB || 0,\n    item.json.lcpScore || 0,\n    item.json.lcpMs || 0,\n    escapeCsv(item.json.dateCaptured || timestamp)\n  ];\n  \n  return row.join(',');\n}).join('\\n');\n\n// Combine header and rows\nconst csvContent = csvHeader + csvRows;\n\n// Return with binary data for writing to file\nreturn [{\n  json: { \n    filename: `lighthouse_results_${timestamp}.csv`\n  },\n  binary: {\n    data: {\n      mimeType: 'text/csv',\n      data: Buffer.from(csvContent).toString('base64')\n    }\n  }\n}];"},"name":"CSV Conversion","type":"n8n-nodes-base.code","typeVersion":2,"position":[840,200],"id":"933051c6-6cf2-431d-bf28-41c515b4b169","alwaysOutputData":true},{"parameters":{"operation":"write","fileName":"/tmp/elc_large_images.csv","options":{"append":true}},"name":"Read/Write Files from Disk","type":"n8n-nodes-base.readWriteFile","typeVersion":1,"position":[1120,200],"id":"bf17368e-edc8-4f69-a31d-25c37662ba09","alwaysOutputData":false},{"parameters":{"triggerTimes":{"item":[{"hour":0}]}},"name":"Cron Trigger1","type":"n8n-nodes-base.cron","typeVersion":1,"position":[-1400,160],"id":"cf2f5f7f-b2e2-49d8-a4a5-bf854a1cb7ab"},{"parameters":{"jsCode":"// Define the initial URLs to process\nconst siteUrl = 'https://www.earthlawcenter.org'; // Base URL\nconst sitemapUrl = `${siteUrl}/sitemap.xml`; // Standard sitemap location\n\n// Return initial URLs to process\nreturn [\n  { json: { url: sitemapUrl, isSitemap: true } },  // First process the sitemap\n  { json: { url: siteUrl, isSitemap: false } }     // Also process the homepage directly\n];"},"name":"Sitemap Crawler1","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1180,60],"id":"2f00c471-681d-42f6-84b0-13ca62f6f619","alwaysOutputData":true},{"parameters":{"url":"={{$json.url}}","options":{}},"name":"HTTP Request1","type":"n8n-nodes-base.httpRequest","typeVersion":4,"position":[-980,60],"id":"dee3472a-f9bd-4b86-b183-ff74578242f1","alwaysOutputData":true},{"parameters":{"jsCode":"// Multi-strategy URL discovery approach\nconst baseUrl = 'https://www.earthlawcenter.org';\n\n// Strategy 1: Include key pages directly (guaranteed to work)\nconst keyPages = [\n  baseUrl,\n  `${baseUrl}/about`,\n  `${baseUrl}/blog`,\n  `${baseUrl}/contact`,\n  `${baseUrl}/programs`,\n  `${baseUrl}/resources`,\n  `${baseUrl}/earth-lawyers-fellowship`\n];\n\n// Return these pages as our initial batch\nconst initialItems = keyPages.map(url => ({\n  json: { \n    url: url,\n    pageUrl: url,  // Include both formats to be safe\n    isSitemap: false,\n    source: 'direct'\n  }\n}));\n\n// Add the sitemap URL as something to process\ninitialItems.push({\n  json: {\n    url: `${baseUrl}/sitemap.xml`,\n    isSitemap: true,\n    source: 'sitemap'\n  }\n});\n\n// Log what we're returning for debugging\nconsole.log(`Returning ${initialItems.length} initial URLs for processing`);\n\nreturn initialItems;"},"name":"Sitemap Parser1","type":"n8n-nodes-base.code","typeVersion":2,"position":[-780,60],"id":"04de0eb6-e3d7-4f5e-af63-775de1b85922","alwaysOutputData":true},{"parameters":{"url":"https://www.earthlawcenter.org/sitemap.xml","options":{}},"name":"Fetch Sitemap Index1","type":"n8n-nodes-base.httpRequest","typeVersion":4,"position":[-1180,260],"id":"b428aabb-4cc0-4199-9e62-4bc10a6ac504","alwaysOutputData":true},{"parameters":{"functionCode":"const xml=(items[0].json.data||items[0].json.body||'');\nif (!xml) return []; \nconst locs=[...xml.matchAll(/<loc>([^<]+)<\\/loc>/g)].map(m=>m[1]);\nconst isIndex=xml.includes('<sitemapindex');\nreturn locs\n  .filter(u=>u.includes('earthlawcenter.org'))\n  .filter(u=>!isIndex||u.endsWith('.xml'))\n  .map(u=>({json:{[isIndex?'sitemapUrl':'pageUrl']:u}}));"},"name":"Parse Sitemap Index1","type":"n8n-nodes-base.function","typeVersion":1,"position":[-980,260],"id":"baaf5712-0f66-4fba-be05-c594d627c0fb","alwaysOutputData":true},{"parameters":{"dataType":"string","value1":"={{$json.pageUrl}}","rules":{"rules":[{"operation":"regex","value2":"."}]}},"name":"Switch Sitemap vs Page1","type":"n8n-nodes-base.switch","typeVersion":1,"position":[-780,240],"id":"857f4147-425f-48b9-9ac2-edc4ffe5d0fe","alwaysOutputData":true},{"parameters":{"options":{}},"type":"n8n-nodes-base.splitInBatches","typeVersion":3,"position":[-180,140],"id":"75c8469e-29c7-4076-b010-a382f9236210","name":"Loop Over Items1"},{"parameters":{"jsCode":"// Get the input item that's being processed\nconst inputItem = $input.item;\n\n// Extract URL from multiple possible fields\nlet pageUrl = inputItem.json.pageUrl || inputItem.json.url || '';\n\n// Always ensure we have data\nconsole.log('Processing URL:', pageUrl);\n\nif (!pageUrl || pageUrl === '') {\n  console.log('No URL found, using fallback');\n  pageUrl = 'https://www.earthlawcenter.org';\n}\n\ntry {\n  // Normalize the URL if needed\n  if (!pageUrl.startsWith('http')) {\n    pageUrl = 'https://www.earthlawcenter.org' + (pageUrl.startsWith('/') ? '' : '/') + pageUrl;\n  }\n  \n  // Always return something with the pageUrl field explicitly set\n  return {\n    json: {\n      pageUrl: pageUrl,\n      source: inputItem.json.source || 'unknown'\n    }\n  };\n} catch (error) {\n  console.log(`Error processing URL: ${error.message}`);\n  // Even on error, return the homepage as fallback\n  return {\n    json: {\n      pageUrl: 'https://www.earthlawcenter.org',\n      source: 'fallback'\n    }\n  };\n}"},"name":"Validate pageUrl1","type":"n8n-nodes-base.code","typeVersion":2,"position":[0,0],"id":"d82a6041-4ecc-4dc1-b73d-0c4950156842","alwaysOutputData":true},{"parameters":{"command":"=CHROME_PATH=/usr/bin/chromium-browser PATH=$PATH:/usr/local/bin lighthouse {{$json.pageUrl}} --chrome-flags=\"--headless --no-sandbox --disable-gpu --disable-dev-shm-usage --disable-software-rasterizer --disable-extensions\" --output=json --only-categories=performance > /tmp/lighthouse-result.json && cat /tmp/lighthouse-result.json | head -c 1000000"},"name":"Local Lighthouse CLI1","type":"n8n-nodes-base.executeCommand","typeVersion":1,"position":[220,0],"id":"3592b2ec-9ca8-4880-b258-5aee3ad3f70d","alwaysOutputData":true},{"parameters":{"conditions":{"string":[{"value1":"={{$json.stdout || $json.standardOutput || $json.data}}","operation":"isNotEmpty"}]}},"name":"Has Lighthouse Output?1","type":"n8n-nodes-base.if","typeVersion":1,"position":[540,0],"id":"8da67d70-d676-4297-bbb1-a5b4826f792e","alwaysOutputData":true},{"parameters":{"jsCode":"// Extract Lighthouse LCP data\nfunction processLighthouseOutput() {\n  // Get the input data\n  const rawOutput = $json.stdout || '';\n  \n  // CHANGE 1: Use pageUrl from current context, but also use Validate PageUrl1's data when available\n  // Get pageUrl from the current context\n  const pageUrl = $json.pageUrl || '';\n  // Store the validated pageUrl for use in error handling - critical for pipeline integrity\n  const validatedPageUrl = pageUrl;\n  \n  console.log(`Processing Lighthouse data for: ${pageUrl}`);\n  \n  // Initialize variables\n  let lcpScore = 0.5; \n  let lcpMs = 2000;\n  let lcpImageUrl = '';  // Start with empty string\n  let foundImages = 0;\n  const allImageUrls = [];\n  let errorStatus = 'none'; // Track error status for downstream handling\n  \n  try {\n    // Parse the Lighthouse JSON output\n    const lighthouseData = JSON.parse(rawOutput);\n    \n    // Extract LCP score and timing from the audit\n    if (lighthouseData.audits && lighthouseData.audits['largest-contentful-paint']) {\n      const lcpAudit = lighthouseData.audits['largest-contentful-paint'];\n      lcpScore = lcpAudit.score || 0.5;\n      lcpMs = lcpAudit.numericValue || 2000;\n      \n      // Try to extract the LCP element details\n      if (lcpAudit.details && lcpAudit.details.items && lcpAudit.details.items.length > 0) {\n        const lcpElement = lcpAudit.details.items[0];\n        \n        if (lcpElement.node && lcpElement.node.nodeLabel) {\n          // Check if it's an image element\n          if (lcpElement.node.nodeLabel.includes('img')) {\n            // Extract URL from the node description\n            const urlMatch = lcpElement.node.snippet.match(/src=[\"']([^\"']+)[\"']/i);\n            if (urlMatch && urlMatch[1]) {\n              lcpImageUrl = urlMatch[1];\n              foundImages = 1;\n              console.log('Found LCP image:', lcpImageUrl);\n            }\n          }\n        }\n      }\n    }\n    \n    // If no LCP image found yet, check network requests\n    if (!lcpImageUrl) {\n      if (lighthouseData.audits && lighthouseData.audits['network-requests'] && \n          lighthouseData.audits['network-requests'].details && \n          lighthouseData.audits['network-requests'].details.items) {\n        \n        const requests = lighthouseData.audits['network-requests'].details.items;\n        \n        // Find image requests and sort by size (largest first)\n        const imageRequests = requests\n          .filter(req => req.resourceType === 'Image' || (req.mimeType && req.mimeType.startsWith('image/')))\n          .sort((a, b) => (b.transferSize || 0) - (a.transferSize || 0));\n        \n        if (imageRequests.length > 0) {\n          lcpImageUrl = imageRequests[0].url;\n          foundImages = imageRequests.length;\n          console.log('Found image from network requests:', lcpImageUrl);\n        }\n      }\n    }\n    \n    // Search for images in the entire page content as another approach\n    if (!lcpImageUrl) {\n      // Look for any image URLs in the data\n      const fullString = JSON.stringify(lighthouseData);\n      const urlPattern = /https?:\\/\\/[^\"']+\\.(jpg|jpeg|png|gif|webp)/gi;\n      const matches = fullString.match(urlPattern) || [];\n      \n      if (matches.length > 0) {\n        // Filter out common logos/icons\n        const filteredMatches = matches.filter(url => !url.toLowerCase().includes('logo'));\n        \n        // CHANGE 2: Additional filtering for better image selection\n        // Further filter out very small images, favicons, etc.\n        const likelyContentImages = filteredMatches.filter(url => {\n          const lowerUrl = url.toLowerCase();\n          return !lowerUrl.includes('icon') && \n                 !lowerUrl.includes('avatar') &&\n                 !lowerUrl.includes('button') &&\n                 !lowerUrl.includes('thumb');\n        });\n        \n        if (likelyContentImages.length > 0) {\n          lcpImageUrl = likelyContentImages[0];\n          foundImages = likelyContentImages.length;\n          console.log('Found filtered content image:', lcpImageUrl);\n        } else if (filteredMatches.length > 0) {\n          lcpImageUrl = filteredMatches[0];\n          foundImages = filteredMatches.length;\n          console.log('Found image URL from regex pattern:', lcpImageUrl);\n        } else if (matches.length > 0) {\n          lcpImageUrl = matches[0];\n          foundImages = matches.length;\n        }\n      }\n    }\n  } catch (error) {\n    console.log('Error parsing Lighthouse data:', error.message);\n    errorStatus = 'parse_error';\n    // Continue with default values\n  }\n  \n  // CHANGE 3: Enhanced URL validation with multiple checks\n  // First flag indicates if we're using a fallback URL\n  let usingFallbackUrl = false;\n  \n  // Check for empty or invalid URLs\n  if (!lcpImageUrl || lcpImageUrl.trim() === '') {\n    // Mark that we're using a fallback\n    usingFallbackUrl = true;\n    errorStatus = 'empty_url';\n    \n    // Attempt to find a known good image on the site as fallback\n    if (validatedPageUrl && validatedPageUrl.includes('earthlawcenter.org')) {\n      // Use a known image from the site that's likely to exist\n      lcpImageUrl = 'https://www.earthlawcenter.org/s/resized-image.jpg';\n      console.log('Using site-specific fallback image');\n    } else {\n      // Last resort fallback to a guaranteed valid URL\n      lcpImageUrl = 'https://example.com/image.jpg';\n      console.log('Using generic fallback URL for empty lcpImageUrl');\n    }\n  }\n  \n  // Make sure URL is properly formatted with http/https\n  if (!lcpImageUrl.startsWith('http')) {\n    // Flag that we need to convert the URL\n    let needsConversion = true;\n    \n    // If URL is relative, convert to absolute based on pageUrl\n    try {\n      // Extract domain from pageUrl\n      let domain = '';\n      \n      // Try to get domain from validatedPageUrl first, then fallback to general parsing\n      if (validatedPageUrl && validatedPageUrl.startsWith('http')) {\n        const pageUrlObj = new URL(validatedPageUrl);\n        domain = pageUrlObj.origin;\n      } else if (pageUrl && pageUrl.startsWith('http')) {\n        const pageUrlObj = new URL(pageUrl);\n        domain = pageUrlObj.origin;\n      } else {\n        // Default domain if we can't extract it\n        domain = 'https://www.earthlawcenter.org';\n      }\n      \n      // Join with relative path\n      lcpImageUrl = lcpImageUrl.startsWith('/') \n        ? `${domain}${lcpImageUrl}` \n        : `${domain}/${lcpImageUrl}`;\n      \n      console.log('Converted relative URL to absolute:', lcpImageUrl);\n      needsConversion = false;\n    } catch (e) {\n      console.log('URL parsing failed:', e.message);\n      errorStatus = 'url_conversion_error';\n      // We'll handle this in the next block\n    }\n    \n    // If conversion failed, use fallback\n    if (needsConversion) {\n      usingFallbackUrl = true;\n      lcpImageUrl = 'https://example.com/image.jpg';\n      console.log('URL conversion failed, using fallback URL');\n    }\n  }\n  \n  // CHANGE 4: Additional validation for domain mismatch\n  // This helps catch cross-domain images that might fail CORS or be blocked\n  try {\n    // Check if image is from same domain as page\n    if (validatedPageUrl && lcpImageUrl) {\n      const pageUrlObj = new URL(validatedPageUrl);\n      const imageUrlObj = new URL(lcpImageUrl);\n      \n      // If domains don't match, flag it but don't change the URL yet\n      // (We'll let the Get Image Headers node try first)\n      if (pageUrlObj.hostname !== imageUrlObj.hostname) {\n        console.log('Warning: Image from different domain than page');\n        // Add flag for downstream nodes to handle potential CORS issues\n        errorStatus = 'cross_domain_image';\n      }\n    }\n  } catch (e) {\n    // URL parsing error, just log and continue\n    console.log('Domain comparison error:', e.message);\n  }\n  \n  // Return data with validated URL and error flags for downstream handling\n  const result = {\n    pageUrl: validatedPageUrl || pageUrl,  // Use validated URL when available\n    lcpScore: lcpScore,\n    lcpMs: lcpMs,\n    lcpImageUrl: lcpImageUrl,\n    foundImages: foundImages,\n    usingFallbackUrl: usingFallbackUrl,  // Flag for downstream nodes\n    errorStatus: errorStatus             // Error tracking for downstream nodes\n  };\n  \n  console.log('Final result with validated URL:', JSON.stringify(result));\n  return result;\n}\n\n// Execute the function and return results\nreturn [{ json: processLighthouseOutput() }];"},"name":"Parse Lighthouse Output1","type":"n8n-nodes-base.code","typeVersion":2,"position":[820,0],"id":"99e537d6-73c3-443f-bf40-fd4757934a38","alwaysOutputData":true},{"parameters":{"method":"HEAD","url":"={{$json.lcpImageUrl}}","options":{}},"name":"Get Image Headers1","type":"n8n-nodes-base.httpRequest","typeVersion":4,"position":[80,220],"id":"a257938e-1493-4f65-a6d0-3a4b38acbe9f","alwaysOutputData":true},{"parameters":{"functionCode":"// Get input item (this node receives one item at a time from the loop)\nconst item = $input.item;\n\n// --- Essential Properties from Input ---\n// pageUrl should have been validated by 'Validate pageUrl1'\n// lcpImageUrl, lcpScore, lcpMs, usingFallbackUrl, errorStatus should come from 'Parse Lighthouse Output1'\n// csvFileName should have been added by 'Add CSV Info to URLs'\n// Potentially: statusCode, headers, error, url (as lcpImageUrl) from 'Get Image Headers1' if it ran for the LCP image\n\nconst pageUrl = item.json.pageUrl || '';\n\n// If pageUrl is missing after all prior validation, something is wrong.\n// Return a structured item indicating this issue.\nif (!pageUrl) {\n  console.warn('Compute Stats: Received item with no pageUrl. This should not happen after Validate pageUrl1.');\n  return {\n    json: {\n      ...item.json, // Pass through what we have\n      pageUrl: '',\n      lcpImageUrl: '',\n      imageSizeKB: 0,\n      lcpScore: item.json.lcpScore || 0,\n      lcpMs: item.json.lcpMs || 0,\n      dateCaptured: new Date().toISOString(),\n      hasValidImage: false,\n      errorReason: item.json.errorReason || 'skipped_no_pageurl',\n      usingFallbackUrl: item.json.usingFallbackUrl !== undefined ? item.json.usingFallbackUrl : true,\n      // Ensure snippet fields exist for consistent structure downstream\n      preloadSnippet: '',\n      responsiveImgSnippet: '',\n      pictureSnippet: '',\n      headerSnippet: ''\n    }\n  };\n}\n\n// --- Initialize/Carry Over Core LCP Data ---\nlet lcpImageUrl = item.json.lcpImageUrl || '';\nlet currentUsingFallbackUrl = item.json.usingFallbackUrl || false; // From Parse Lighthouse Output\nlet currentErrorReason = item.json.errorStatus || 'none';      // From Parse Lighthouse Output\n\n// --- Check Results from 'Get Image Headers1' (if it ran for the LCP image) ---\n// The 'Get Image Headers1' node (HTTP Request) adds 'url', 'statusCode', 'headers', 'error' to item.json\n// We need to check if these properties relate to the *current lcpImageUrl*.\nconst httpInfoIsForLcpImage = item.json.url && item.json.url === lcpImageUrl;\nconst httpErrorForLcpImage = httpInfoIsForLcpImage && item.json.error;\nconst httpBadStatusCodeForLcpImage = httpInfoIsForLcpImage && item.json.statusCode && item.json.statusCode >= 400;\n\nif (httpErrorForLcpImage || httpBadStatusCodeForLcpImage) {\n  console.log(`Compute Stats: 'Get Image Headers1' failed for LCP image ${lcpImageUrl} (Status: ${item.json.statusCode}, Error: ${item.json.error ? item.json.error.message : 'N/A'}). Applying fallback.`);\n  currentUsingFallbackUrl = true;\n  // Update errorReason if it's a new/more specific error, otherwise keep existing.\n  currentErrorReason = (currentErrorReason === 'none' || currentErrorReason === 'cross_domain_image') ? 'http_error_lcp_image' : currentErrorReason;\n\n  // Apply fallback LCP image URL\n  if (pageUrl.includes('earthlawcenter.org')) {\n    lcpImageUrl = 'https://www.earthlawcenter.org/s/resized-image.jpg';\n  } else {\n    lcpImageUrl = 'https://example.com/image.jpg';\n  }\n  // Mark that the original HTTP headers from 'Get Image Headers1' are now invalid for size calculation\n  // by effectively nullifying them for the next step. We'll delete them from the final output later.\n  item.json.headers = null; // So the next block doesn't use them for size.\n}\n\n// --- Determine if Final LCP Image is a Default/Fallback ---\nconst isDefaultOrFallbackImage =\n  lcpImageUrl.includes('example.com/image.jpg') ||\n  lcpImageUrl === '' ||\n  !lcpImageUrl.startsWith('http');\n\n// --- Calculate Image Size ---\nlet imageSizeKB = 0;\nif (!isDefaultOrFallbackImage && item.json.headers && httpInfoIsForLcpImage && !httpBadStatusCodeForLcpImage && !httpErrorForLcpImage) {\n  // Only use headers if they are for the current LCP image and the request was successful\n  const contentLengthHeader = item.json.headers['content-length'] || item.json.headers['Content-Length'];\n  if (contentLengthHeader) {\n    imageSizeKB = Math.round(parseInt(contentLengthHeader, 10) / 1024) || 0;\n  } else {\n    console.log(`Compute Stats: No content-length header for ${lcpImageUrl}, size set to 0KB.`);\n  }\n} else if (!isDefaultOrFallbackImage && item.json.imageSizeKB) {\n  // If not a default image and we don't have fresh headers, but imageSizeKB was somehow already set\n  // (e.g., if Parse Lighthouse Output could estimate it, though it usually doesn't), use that.\n  imageSizeKB = item.json.imageSizeKB;\n}\n// Otherwise, imageSizeKB remains 0 (for default/fallback or no size info).\n\n// --- Construct the Output JSON ---\n// Start with all existing properties from the input item's JSON (passthrough csvFileName etc.)\n// Then, override or add the properties calculated/handled in this node.\nconst outputJson = {\n  ...item.json,\n  pageUrl: pageUrl, // Already validated\n  lcpImageUrl: isDefaultOrFallbackImage ? '' : lcpImageUrl, // Final LCP image URL\n  imageSizeKB: imageSizeKB,\n  // lcpScore, lcpMs are from Parse Lighthouse Output and should be in item.json already\n  dateCaptured: new Date().toISOString(),\n  hasValidImage: !isDefaultOrFallbackImage && lcpImageUrl !== '',\n  errorReason: currentErrorReason, // Final error reason\n  usingFallbackUrl: currentUsingFallbackUrl // Final fallback status\n};\n\n// --- Clean up Temporary/Intermediate Properties from Previous Nodes ---\n// These were used for logic within this node but are not needed in the final clean data object.\ndelete outputJson.url; // From 'Get Image Headers1' (was its input URL)\ndelete outputJson.method; // From 'Get Image Headers1'\ndelete outputJson.response; // From 'Get Image Headers1'\n// 'error' field from Get Image Headers1 (if any) has been processed into errorReason\nif (item.json.error && httpInfoIsForLcpImage) delete outputJson.error;\ndelete outputJson.body; // From 'Get Image Headers1'\ndelete outputJson.data; // From 'Get Image Headers1'\ndelete outputJson.headers; // From 'Get Image Headers1'\ndelete outputJson.statusCode; // From 'Get Image Headers1'\ndelete outputJson.statusMessage; // From 'Get Image Headers1'\n\n// 'errorStatus' was the input field from 'Parse Lighthouse Output1', now superseded by 'errorReason'\ndelete outputJson.errorStatus;\n// 'stdout', 'stderr', 'exitCode', 'command' are from 'Local Lighthouse CLI1'\ndelete outputJson.stdout;\ndelete outputJson.stderr;\ndelete outputJson.exitCode;\ndelete outputJson.command;\n// 'foundImages' from 'Parse Lighthouse Output1' is informational for that step\ndelete outputJson.foundImages;\n\n\nconsole.log(`Compute Stats Completed for ${pageUrl} - Final LCP Image: ${outputJson.lcpImageUrl || 'None'}, Size: ${outputJson.imageSizeKB}KB, Fallback: ${outputJson.usingFallbackUrl}, Error: ${outputJson.errorReason}`);\n\nreturn { json: outputJson };"},"name":"Compute Stats & Snippet1","type":"n8n-nodes-base.function","typeVersion":1,"position":[440,200],"id":"438eae13-c6e1-4ceb-aa78-81a2c56abaa5","alwaysOutputData":true},{"parameters":{"jsCode":"// Mobile Image Optimization Function\nfunction optimizeImagesForMobile(itemJson) {\n  // Destructure with defaults to prevent errors if properties are missing,\n  // though previous nodes should ensure they exist.\n  const { pageUrl = 'Unknown Page', lcpImageUrl = '', csvFileName = '' } = itemJson; // Ensure pageUrl exists for messages\n  let newItemJson = { ...itemJson }; // Start with a copy to preserve all passed-through fields like csvFileName\n\n  // Handle cases where LCP image is not found, is a fallback, or is empty\n  if (!lcpImageUrl || lcpImageUrl.includes('example.com/image.jpg') || lcpImageUrl === '') {\n    newItemJson.preloadSnippet = '';\n    newItemJson.responsiveImgSnippet = '';\n    newItemJson.pictureSnippet = '';\n    newItemJson.headerSnippet = `<!-- SEO Mobile Image Optimization for ${pageUrl} - No LCP Image Found -->\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />`;\n    newItemJson.seoOptimizationStatus = 'no_lcp_image';\n    console.log(`Snippet Creator: No valid LCP image for ${pageUrl}. Status: no_lcp_image`);\n    return newItemJson; // Return the item with 'no_lcp_image' status and empty snippets\n  }\n\n  // If we have a valid lcpImageUrl, proceed with snippet generation\n  try {\n    const fileExtension = lcpImageUrl.split('.').pop().toLowerCase();\n    const isModernFormat = ['webp', 'avif'].includes(fileExtension);\n\n    let basePath = lcpImageUrl;\n    const queryParamIndex = basePath.indexOf('?');\n    if (queryParamIndex !== -1) {\n      basePath = basePath.substring(0, queryParamIndex);\n    }\n\n    function getOrigin(url) {\n      if (!url || typeof url !== 'string') return '';\n      const originMatch = url.match(/^(https?:\\/\\/[^/]+)/i);\n      return originMatch ? originMatch[1] : '';\n    }\n\n    const sizes = [\n      { width: 320, label: 'small' },\n      { width: 768, label: 'medium' },\n      { width: 1024, label: 'large' },\n      { width: 1920, label: 'xlarge' }\n    ];\n\n    newItemJson.preloadSnippet = `<link rel=\"preload\" href=\"${lcpImageUrl}\" as=\"image\" media=\"(max-width: 768px)\" fetchpriority=\"high\" />`;\n\n    let srcsetEntries = '';\n    let sizesAttr = '';\n\n    // Check for Squarespace or known CDN patterns that allow URL-based resizing.\n    // This regex is a bit more general for Squarespace format params.\n    const isSquarespaceCdn = /images\\.squarespace-cdn\\.com/.test(lcpImageUrl) || /static\\d*\\.squarespace\\.com/.test(lcpImageUrl);\n\n    if (isSquarespaceCdn) {\n        // More robust base path for Squarespace: remove existing format query params and width suffixes\n        let sqBasePath = basePath.replace(/\\?format=.*$/, '').replace(/\\/\\d+w$/, '');\n        srcsetEntries = sizes.map(size =>\n            `${sqBasePath}?format=${size.width}w ${size.width}w`\n        ).join(', ');\n        sizesAttr = `(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw`;\n    } else if (lcpImageUrl.includes('cdn.com')) { // Generic cdn.com, less certain resizing\n        srcsetEntries = sizes.map(size =>\n        `${basePath.replace(/\\.(jpg|jpeg|png|gif|webp|avif)$/i, `-${size.label}.$1`)} ${size.width}w`\n        ).join(', ');\n        sizesAttr = `(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw`;\n    }\n    else {\n      srcsetEntries = `${lcpImageUrl} 1x`; // Fallback for unknown URL structures\n      sizesAttr = `100vw`;\n    }\n    \n    newItemJson.responsiveImgSnippet = `<img src=\"${lcpImageUrl}\" \\n    srcset=\"${srcsetEntries}\" \\n    sizes=\"${sizesAttr}\" \\n    alt=\"LCP Image for ${pageUrl}\" \\n    loading=\"eager\" \\n    width=\"100%\" \\n    height=\"auto\" \\n    fetchpriority=\"high\" />`;\n\n    newItemJson.pictureSnippet = '';\n    // Ensure basePath doesn't end with '.' after stripping extension if it had one\n    const baseForWebp = basePath.replace(/\\.[^/.]+$/, \"\");\n\n    if (!isModernFormat && fileExtension.match(/^(jpg|jpeg|png|gif)$/i) && baseForWebp !== basePath ) {\n      newItemJson.pictureSnippet = `<picture>\\n    <source type=\"image/webp\" srcset=\"${baseForWebp}.webp 1x\" />\\n    <source type=\"image/${fileExtension}\" srcset=\"${lcpImageUrl} 1x\" />\\n    <img src=\"${lcpImageUrl}\" alt=\"LCP Image for ${pageUrl}\" loading=\"eager\" width=\"100%\" height=\"auto\" />\\n</picture>`;\n    }\n\n    const imageOrigin = getOrigin(lcpImageUrl);\n    newItemJson.headerSnippet = `<!-- SEO Mobile Image Optimization for ${pageUrl} -->\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n${imageOrigin ? `<link rel=\"preconnect\" href=\"${imageOrigin}\" />` : ''}\\n${newItemJson.preloadSnippet}\\n<style>\\n  img.lcp-image { aspect-ratio: 16/9; object-fit: cover; }\\n  @media (max-width: 768px) { img.lcp-image { content-visibility: auto; } }\\n</style>`;\n    \n    newItemJson.seoOptimizationStatus = 'applied';\n    console.log(`Snippet Creator: Successfully applied snippets for ${pageUrl}, LCP: ${lcpImageUrl}`);\n\n  } catch (error) {\n    console.error(`Snippet Creator: Error processing ${pageUrl} (LCP: ${lcpImageUrl}): ${error.message}`, error.stack);\n    // In case of error, ensure defined state for snippet fields\n    newItemJson.preloadSnippet = newItemJson.preloadSnippet || ''; // Keep if already set by earlier part of try\n    newItemJson.responsiveImgSnippet = newItemJson.responsiveImgSnippet || '';\n    newItemJson.pictureSnippet = newItemJson.pictureSnippet || '';\n    newItemJson.headerSnippet = `<!-- Error generating snippets for ${pageUrl} -->`;\n    newItemJson.seoOptimizationStatus = 'error_in_snippet_generation';\n  }\n  \n  return newItemJson;\n}\n\n// Process the input data\nconst inputItemJson = $input.item.json;\nconst resultJson = optimizeImagesForMobile(inputItemJson);\n\n// Ensure all expected snippet fields are at least empty strings if not populated\nresultJson.preloadSnippet = resultJson.preloadSnippet || '';\nresultJson.responsiveImgSnippet = resultJson.responsiveImgSnippet || '';\nresultJson.pictureSnippet = resultJson.pictureSnippet || '';\nresultJson.headerSnippet = resultJson.headerSnippet || '';\nresultJson.seoOptimizationStatus = resultJson.seoOptimizationStatus || 'unknown';\n\n\nreturn { json: resultJson };"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[540,440],"id":"e71f9c7c-eb87-4bec-b05c-85b7ef807333","name":"Snippet creator"},{"parameters":{"jsCode":"// Get current item\nconst currentItem = $input.item.json;\n\n// Create row data for CSV format\nconst headers = Object.keys(currentItem);\nconst rowData = Object.values(currentItem).map(value => {\n  // Handle strings with commas or quotes\n  if (typeof value === 'string' && (value.includes(',') || value.includes('\"'))) {\n    return `\"${value.replace(/\"/g, '\"\"')}\"`;\n  }\n  return value !== undefined ? value : '';\n}).join(',');\n\n// Create complete CSV content for this item\n// Include header row flag to help downstream nodes\nconst isFirstItem = $input.item.index === 0;\n\n// Create binary output suitable for the Read/Write node\nreturn {\n  json: {\n    ...currentItem,\n    isFirstItem: isFirstItem,\n    csvRow: rowData\n  },\n  binary: {\n    data: {\n      data: Buffer.from(rowData + '\\n').toString('base64'),\n      mimeType: 'text/csv',\n      fileName: `row_${$input.item.index || 0}.csv`\n    }\n  }\n};"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[840,480],"id":"a063a1a7-578d-4515-b5c4-ac700e26b407","name":"Workflow Data Collection"},{"parameters":{"command":"=/data/lighthouse/store_lighthouse_data.sh \"{{$json.pageUrl}}\" \"{{$json.lcpImageUrl}}\" {{$json.imageSizeKB}} {{$json.lcpScore}} {{$json.lcpMs}} \"{{$json.preloadSnippet}}\" \"{{$json.responsiveImgSnippet}}\""},"name":"Store in Database and CSV","type":"n8n-nodes-base.executeCommand","typeVersion":1,"position":[1200,400],"id":"2fbbde03-4808-459a-ba1e-71dce1bc81db","alwaysOutputData":true},
{
    "parameters":{
      "jsCode":"// Extract URL from webhook input\nconst input = $input.item;\n\n// If we received data from the webhook\nif (input && input.json && (input.json.url || input.json.pageUrl)) {\n  // Get URL from request body\n  const url = input.json.url || input.json.pageUrl;\n  console.log(`Received URL from webhook: ${url}`);\n  \n  return {\n    json: {\n      url: url,\n      pageUrl: url,\n      source: 'webhook',\n      isSitemap: false\n    }\n  };\n} else {\n  // Default URL if none provided\n  console.log('No URL found in webhook, using default');\n  return {\n    json: {\n      url: 'https://www.earthlawcenter.org',\n      pageUrl: 'https://www.earthlawcenter.org',\n      source: 'webhook_default',\n      isSitemap: false\n    }\n  };\n}"
    },
    "name":"Process Webhook Input",
    "type":"n8n-nodes-base.code",
    "typeVersion":2,
    "position":[-1220,20],
    "id":"04de0eb6-0000-0000-0000-000000000001",
    "alwaysOutputData":true
}
],"connections":{"Filter":{"main":[[{"node":"Loop Over Items1","type":"main","index":0}]]},"Merge URL Sources":{"main":[[{"node":"Filter","type":"main","index":0}]]},"Data validation node":{"main":[[{"node":"CSV Conversion","type":"main","index":0}]]},"CSV Conversion":{"main":[[{"node":"Read/Write Files from Disk","type":"main","index":0}]]},"Read/Write Files from Disk":{"main":[[{"node":"Loop Over Items1","type":"main","index":0}]]},"Cron Trigger1":{"main":[[{"node":"Sitemap Crawler1","type":"main","index":0},{"node":"Fetch Sitemap Index1","type":"main","index":0}]]},"Sitemap Crawler1":{"main":[[{"node":"HTTP Request1","type":"main","index":0}]]},"HTTP Request1":{"main":[[{"node":"Sitemap Parser1","type":"main","index":0}]]},"Sitemap Parser1":{"main":[[{"node":"Merge URL Sources","type":"main","index":0}]]},"Fetch Sitemap Index1":{"main":[[{"node":"Parse Sitemap Index1","type":"main","index":0}]]},"Parse Sitemap Index1":{"main":[[{"node":"Switch Sitemap vs Page1","type":"main","index":0}]]},"Switch Sitemap vs Page1":{"main":[[{"node":"Merge URL Sources","type":"main","index":1}]]},"Loop Over Items1":{"main":[[{"node":"Store in Database and CSV","type":"main","index":0}],[{"node":"Validate pageUrl1","type":"main","index":0}]]},"Validate pageUrl1":{"main":[[{"node":"Local Lighthouse CLI1","type":"main","index":0}]]},"Local Lighthouse CLI1":{"main":[[{"node":"Has Lighthouse Output?1","type":"main","index":0}]]},"Has Lighthouse Output?1":{"main":[[{"node":"Parse Lighthouse Output1","type":"main","index":0}]]},"Parse Lighthouse Output1":{"main":[[{"node":"Get Image Headers1","type":"main","index":0}]]},"Get Image Headers1":{"main":[[{"node":"Snippet creator","type":"main","index":0},{"node":"Compute Stats & Snippet1","type":"main","index":0}]]},"Compute Stats & Snippet1":{"main":[[{"node":"Data validation node","type":"main","index":0},{"node":"Workflow Data Collection","type":"main","index":0}]]},"Snippet creator":{"main":[[{"node":"Store in Database and CSV","type":"main","index":0},{"node":"Workflow Data Collection","type":"main","index":0}]]},"Workflow Data Collection":{"main":[[{"node":"Read/Write Files from Disk","type":"main","index":0}]]},
"Webhook Trigger":{"main":[[{"node":"Process Webhook Input","type":"main","index":0}]]},
"Process Webhook Input":{"main":[[{"node":"Validate pageUrl1","type":"main","index":0}]]}
},"settings":{"executionOrder":"v1"},"staticData":null,"meta":{"templateCredsSetupCompleted":true,"instanceId":"e33594be36242609bb1a95805f789dc1164bcf40ccc82d7af4d8c5cbfef36e0d"},"pinData":{},"versionId":"2537a7d3-33cb-4e30-a78f-9ab8cb1c2a0b","triggerCount":1,"tags":[]}]